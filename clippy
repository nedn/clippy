#!/usr/bin/env python3

import argparse
import json
import os
import openai  # Import the openai library
import sys # Import the sys module

# Configuration file location (in user's home directory)
CONFIG_DIR = os.path.expanduser("~/.clippy")
CONFIG_FILE = os.path.join(CONFIG_DIR, "config.json")

def load_config():
    """Loads configuration from the config file."""
    if not os.path.exists(CONFIG_FILE):
        return {}
    try:
        with open(CONFIG_FILE, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {}

def save_config(config):
    """Saves configuration to the config file."""
    os.makedirs(CONFIG_DIR, exist_ok=True)
    with open(CONFIG_FILE, 'w') as f:
        json.dump(config, f, indent=4)

def set_model(args):
    """Sets the OpenAI model and API key."""
    model_api_key = args.model_api.split(":", 1)
    if len(model_api_key) != 2:
        print("Error: Invalid model and API key format. Use <model_name>:<api_key>")
        return

    model_name, api_key = model_api_key
    config = load_config()
   # Initialize models dict if it doesn't exist
    if 'models' not in config:
        config['models'] = {}
    
    # Store the model configuration
    config['models'][model_name] = {
        'api_key': api_key
    }
    
    # Set as default if requested or if it's the only model
    if args.default or len(config['models']) == 1:
        config['default_model'] = model_name
        print(f"Model '{model_name}' set as default.")
    
    save_config(config)
    print(f"Model '{model_name}' configured successfully.")


def get_base_url(model_name):
    """
    Determines the base URL for the OpenAI client based on the model name.
    """
    if model_name.startswith("gpt-"): # OpenAI models (e.g., gpt-4o, gpt-3.5-turbo)
        return None # No base_url needed for official OpenAI API
    elif model_name.startswith("gemini-"): # Google models (using OpenAI compatible endpoint)
        return "https://generativelanguage.googleapis.com/v1beta/openai/"
    elif model_name.startswith("claude-"): # Anthropic models (assuming they might use a different base URL if accessed via OpenAI endpoint - adjust if needed)
      return "https://api.anthropic.com/"
    else:
        print(f"Warning: Unknown model prefix for '{model_name}'. Assuming OpenAI compatible API.")
        return None # Default to OpenAI base URL or no base_url if model prefix is not recognized


def ask_ai(prompt, model_name, api_key, system_prompt=None):
    """
    Interacts with the AI API, supporting different providers.
    """
    print(f"Sending prompt to model '{model_name}'...")

    base_url = get_base_url(model_name) # Get the base URL based on the model name

    client = openai.OpenAI(
        api_key=api_key,
        base_url=base_url # base_url will be None for OpenAI, or set for Google/Anthropic
    )

    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt}) # Simple user message. You can expand this for system messages etc.

    try:
        response = client.chat.completions.create( # Use openai.chat.completions.create for chat models
            model=model_name,
            messages=messages,
            # Add other parameters as needed, e.g., temperature, max_tokens, etc.
        )

        # --- Parse OpenAI Response ---
        if response.choices:
            ai_answer = response.choices[0].message.content
            return ai_answer
        else:
            return "No valid answer received from API."

    except openai.APIError as e: # Catch OpenAI API errors
        print(f"Error communicating with API: {e}")
        return None
    except Exception as e: # Catch other potential exceptions
        print(f"An unexpected error occurred: {e}")
        return None


_SYSTEM_PROMPT = """
You are a helpful command-line assistant.  Please provide concise and well-formatted responses that are easy to read in a terminal.

Specifically:

- **Be brief and to the point.** Avoid unnecessary conversational fluff or lengthy explanations unless specifically asked for.
- **Format for readability in a terminal.** Use simple formatting like:
    - **Bold text** using markdown syntax `**bold text**` for emphasis where helpful.
    - **Lists** using markdown list syntax (`- item` or `1. item`) for itemized information.
    - **Code blocks** using markdown code block syntax (``` ```) to present code or commands clearly.
- **Keep lines reasonably short.**  Avoid extremely long lines that might wrap awkwardly in terminals with limited width.
- **Focus on providing the requested information directly.**  Assume the user is looking for quick, actionable answers.

Your goal is to be a helpful and efficient assistant that provides clear, concise, and well-formatted information suitable for a command-line environment.
"""


def ask(args):
    """Asks a question to the AI model."""
    config = load_config()
    
    if 'models' not in config or not config['models']:
        print("Error: No models configured. Please use 'clippy set_model <model_name>:<api_key>' first.")
        return
    
    # Use specified model or default model
    model_name = args.model or config.get('default_model')
    if not model_name:
        print("Error: No model specified and no default model set. Please specify a model with --model or set a default.")
        return
    
    if model_name not in config['models']:
        print(f"Error: Model '{model_name}' not found in configuration. Available models: {', '.join(config['models'].keys())}")
        return
    
    api_key = config['models'][model_name]['api_key']

    if not model_name or not api_key: # API key is now required
        print("Error: Model and API key not set. Please use 'clippy set_model <model_name>:<api_key>' first.")
        return

    prompt_parts = args.prompt
    stdin_content = ""

    if not sys.stdin.isatty(): # Check if stdin is not a terminal (i.e., data is being piped in)
        stdin_content = sys.stdin.read()
        if stdin_content:
            prompt_parts.append(stdin_content) # Append stdin content to the prompt

    prompt = " ".join(prompt_parts) # Join all parts of the prompt

    if not prompt.strip(): # Check if prompt is empty after potentially adding stdin
        print("Error: Please provide a prompt to ask, either as command line arguments or via stdin.")
        return

    ai_response = ask_ai(prompt, model_name, api_key,
                         system_prompt=_SYSTEM_PROMPT)
    if ai_response:
        print("\nAI Response:\n")
        print(ai_response.strip()) # Remove leading/trailing whitespace for cleaner output

def list_models(args):
    """Lists all configured models and indicates the default model."""
    config = load_config()
    
    if 'models' not in config or not config['models']:
        print("No models configured. Use 'clippy set_model <model_name>:<api_key>' to add a model.")
        return
    
    default_model = config.get('default_model')
    print("\nConfigured Models:")
    for model_name in config['models']:
        prefix = "* " if model_name == default_model else "  "
        print(f"{prefix}{model_name}")
    
    if default_model:
        print("\n* indicates default model")

def change_default(args):
    """Changes the default model to another existing model."""
    config = load_config()
    
    if 'models' not in config or not config['models']:
        print("No models configured. Use 'clippy set_model <model_name>:<api_key>' first.")
        return
    
    model_name = args.model
    if model_name not in config['models']:
        print(f"Error: Model '{model_name}' not found in configuration.")
        print(f"Available models: {', '.join(config['models'].keys())}")
        return
    
    config['default_model'] = model_name
    save_config(config)
    print(f"Default model changed to '{model_name}'.")


def main():
    parser = argparse.ArgumentParser(description="Clippy: Your AI Command-Line Assistant (OpenAI, Google, Anthropic)")
    subparsers = parser.add_subparsers(title='commands', dest='command')

    # set_model command
    set_model_parser = subparsers.add_parser('set_model', help='Set an AI model and API key')
    set_model_parser.add_argument('model_api', help='Model name and API key in the format <model_name>:<api_key>')
    set_model_parser.add_argument('--default', '-d', action='store_true', help='Set this model as the default')
    set_model_parser.set_defaults(func=set_model)

    # ask command
    ask_parser = subparsers.add_parser('ask', help='Ask a question to the AI model')
    ask_parser.add_argument('prompt', nargs='+', help='The prompt to ask the AI')
    ask_parser.add_argument('--model', '-m', help='Specify which model to use (defaults to configured default model)')
    ask_parser.set_defaults(func=ask)

    # list_models command
    list_models_parser = subparsers.add_parser('list_models', help='List all configured models')
    list_models_parser.set_defaults(func=list_models)

    # change default model command
    change_default_parser = subparsers.add_parser('set_default', help='Change the default model')
    change_default_parser.add_argument('model', help='Name of the model to set as default')
    change_default_parser.set_defaults(func=change_default)

    args = parser.parse_args()

    if args.command:
        args.func(args)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
